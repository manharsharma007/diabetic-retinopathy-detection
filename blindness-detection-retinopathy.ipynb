{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport os\nfrom zipfile import ZipFile\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom keras import layers\nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import np_utils, to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, ZeroPadding2D, BatchNormalization,Activation\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras import regularizers, optimizers\nfrom keras.applications import DenseNet121\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import class_weight, shuffle\nfrom PIL import Image, ImageEnhance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 10\nIMG_SIZE = 350","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest_data = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n\nx = train_data['id_code']\ny = train_data['diagnosis']\n\nx, y = shuffle(x, y, random_state=8)\n\ny = to_categorical(y, num_classes=5)\ntrain_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2,\n                                                      stratify=y, random_state=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n\n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef edgeCanny(img):\n    \n    red,green,blue = cv2.split(img)\n    \n    final_red = cv2.Canny(red, 5, 205)\n    final_red = red + final_red\n    \n    final_green = cv2.Canny(green, 5, 205)\n    final_green = green + final_green\n    \n    final_blue = cv2.Canny(blue, 5, 205)\n    final_blue = blue + final_blue\n    \n    img = cv2.merge([final_red, final_green, final_blue])\n    \n    return img\n    \n\ndef prepare_Images(img):\n    img = cv2.imread(img, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (450, 450))\n    \n    img = crop_image_from_gray(img)\n    \n    img = edgeCanny(img)\n    \n    #img = cv2.equalizeHist(img)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , 35) ,-4 ,128)\n    \n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = train_x.shape[0]\nx_train = np.empty((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(train_x)):\n    x_train[i, :, :, :] = prepare_Images(\n        f'../input/aptos2019-blindness-detection/train_images/{image_id}.png'\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = valid_x.shape[0]\nx_valid = np.empty((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(valid_x)):\n    x_valid[i, :, :, 0] = prepare_Images(\n        f'../input/aptos2019-blindness-detection/train_images/{image_id}.png'\n    )\n    \n    if(i > 10):\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(train_y.shape)\nprint(x_valid.shape)\nprint(valid_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,img in enumerate(x_valid):\n    plt.imshow(img[:,:,0], cmap=\"gray\")\n    plt.title(valid_y[i])\n    plt.show()\n    if(i == 10):\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,img in enumerate(x_valid):\n    plt.imshow(img)\n    plt.title(valid_y[i])\n    plt.show()\n    if(i == 10):\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.15,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n    )\n\n# Using original generator\ndata_generator = create_datagen().flow(x_train, train_y, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building model\ndensenet = DenseNet121(\n    weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(IMG_SIZE,IMG_SIZE,3)\n)\n\ndef build_model():\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.35))\n    model.add(layers.Dense(150,activation='relu'))\n    model.add(layers.Dropout(0.35))\n    model.add(layers.Dense(150,activation='relu'))\n    model.add(layers.Dropout(0.35))\n    model.add(layers.Dense(150,activation='relu'))\n    model.add(BatchNormalization())\n    \n    model.add(layers.Dropout(0.3))\n    model.add(layers.Dense(5, activation='sigmoid'))\n    \n    for layer in model.layers:\n        layer.trainable=True\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=optimizers.adam(lr=0.00005),\n        metrics=['accuracy']\n    )\n    \n    return model\n\nmodel = build_model()\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=6, \n                                   verbose=1, mode='auto', epsilon=0.0001)\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001), metrics=['accuracy'])\n# patient early stopping\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n\nhistory = model.fit_generator(\n    data_generator,\n    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n    epochs=40,\n    validation_data=(x_valid, valid_y),\n    callbacks=[es, reduceLR]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_valid)\n\nfrom sklearn.metrics import accuracy_score, classification_report,confusion_matrix\nscore = round(accuracy_score(valid_y.argmax(axis=1), pred.argmax(axis=1)),2)\nprint(score)\nreport = classification_report(valid_y.argmax(axis=1), pred.argmax(axis=1))\nprint(report)\nconMat = confusion_matrix(valid_y.argmax(axis=1),pred.argmax(axis=1))\nprint(conMat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x_train\ndel x_valid\n# Any results you write to the current directory are saved as output.\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ntest_df.head()\n\nx = test_df['id_code']\ntest_Dataset = []\ndef make_test_data(path):\n    img=prepare_Images(path)\n    test_Dataset.append(img)\n\nfor id_code in tqdm(x):\n    path = os.path.join('../input/aptos2019-blindness-detection/test_images','{}.png'.format(id_code))\n    make_test_data(path)\ntest_image = np.array(test_Dataset)\npred=model.predict(test_image)\npred=np.argmax(pred,axis=1)\npred\n\nsub_df = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nsub_df.head()\n\nsub_df.diagnosis = pred\nsub_df.head()\n\nsub_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(sub_df.diagnosis)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}